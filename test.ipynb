{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### LAST DATE of EXTRACTED DATA\n",
      "[{'extraction_date': '2024-10-09', 'framework': 'HORIZON'}]\n",
      "\n",
      "### LOADING PROJECTS data\n",
      "- no new columns\n",
      "- result -> dowloaded projects:17382, retained projects:17382, pb:0\n",
      "- liste des colonnes conservées:\n",
      "Index(['project_id', 'callId', 'callDeadlineDate', 'typeOfActionCode',\n",
      "       'acronym', 'status_code', 'startDate', 'endDate', 'ecSignatureDate',\n",
      "       'title', 'abstract', 'url', 'topicCode', 'duration', 'total_cost',\n",
      "       'eu_reqrec_grant', 'number_involved', 'framework', 'lastUpdateDate',\n",
      "       'totalGrant', 'nationalContribution', 'otherContribution', 'freekw',\n",
      "       'stage'],\n",
      "      dtype='object')\n",
      "\n",
      "### LOADING PROPOSALS data\n",
      "- no new columns\n",
      "1- empty cols -> Attention ! vérifier les variables manquantes->[]\n",
      "- result -> dowloaded proposals:92864, retained proposals:92864, pb:0\n",
      "\n",
      "### ADD COLS TO PROJECTS FROM PROPOSALS\n",
      "- liste des variables PROJ en plus: ['nationalContribution', 'startDate', 'otherContribution', 'status_code', 'endDate', 'ecSignatureDate', 'stage', 'totalGrant', 'url']\n",
      "- liste des variables PROP en plus: ['isSeo', 'stageExitStatus', 'submissionDate']\n",
      "\n",
      "\n",
      "### PROPOSALS Status\n",
      "- after cleaning -> size prop1 without inadmissible/inegible/etc : 87577\n",
      "\n",
      "### MISSING PROPOSALS\n",
      "2- result: 1030 projets signés absents de la table des propositions\n",
      "3- missing proposals by callId:\n",
      "callId\n",
      "HORIZON-EIC-2024-ACCELERATOR-01    668\n",
      "ERC-2024-STG                       273\n",
      "ERC-2024-POC                        79\n",
      "EIT-KICS-2021                        8\n",
      "HORIZON-CL5-2023-D3-01               2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "- callId already in proposals: callId\n",
      "HORIZON-CL5-2023-D3-01    115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "### MERGED PROPOSALS/PROJECTS\n",
      "- result - merged all: 102295,\n",
      "stage       status_code      \n",
      "evaluated   NO_MONEY             37475\n",
      "            REJECTED             30128\n",
      "            MAIN                 16457\n",
      "successful  SIGNED               13191\n",
      "evaluated   RESERVE               3519\n",
      "successful  CLOSED                 698\n",
      "            UNDER_PREPARATION      690\n",
      "            TERMINATED             109\n",
      "            SUSPENDED               28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "### DATES and YEAR\n",
      "2- calldeadline OK -> year:\n",
      "stage       call_year\n",
      "evaluated   2023         27945\n",
      "            2022         27378\n",
      "            2021         25575\n",
      "            2024          6681\n",
      "successful  2022          5027\n",
      "            2023          4838\n",
      "            2021          4166\n",
      "            2024           685\n",
      "Name: count, dtype: int64\n",
      "\n",
      "### PANELS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zfriant\\Documents\\GitHub\\pcri\\.venv\\pcri-env\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "c:\\Users\\zfriant\\Documents\\GitHub\\pcri\\.venv\\pcri-env\\Lib\\site-packages\\openpyxl\\workbook\\child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- code panel existant pour d'autres programmes que erc/msca: données exportées\n",
      "\n",
      "- size merged after add panels: 102295\n",
      "### TOPICS\n",
      "1 - topics -> 2448\n",
      "2 - divisions -> 3172\n",
      "erc : destination_code à null après traitement\n",
      "['HORIZON-ERC-2021-VICECHAIRS-IBA' 'ERC-2025-NCPS-IBA'\n",
      " 'HORIZON-ERC-2021-arXiv-IBA'\n",
      " 'HORIZON-CL4-2024-SSA-SST-SD-IBA-to-be-deleted'\n",
      " 'HORIZON-CL4-2024-SSA-SST-AE-IBA-to-be-deleted'\n",
      " 'HORIZON-ERC-2023-VICECHAIRS-IBA' 'HORIZON-ERC-2022-VICECHAIRS-IBA'\n",
      " 'HORIZON-CL4-2024-SSA-SST-SP-IBA-to-be-deleted']\n",
      "MSCA : destination_code à null après traitement\n",
      "['HORIZON-MSCA-2021-INCO-01-01' 'HORIZON-MSCA-2021-FRC-IBA'\n",
      " 'HORIZON-MSCA-2022-ALUMNI-IBA' 'HORIZON-MSCA-2024-NCP-01-01'\n",
      " 'HORIZON-MSCA-2023-FTP-01-01' 'HORIZON-MSCA-2022-Ukraine-ART195-IBA'\n",
      " 'HORIZON-MSCA-2021-RR-01-01' 'HORIZON-MSCA-2024-RR-01-01'\n",
      " 'HORIZON-MSCA-2023-BEL-IBA' 'HORIZON-MSCA-2024-UKRAINE-IBA'\n",
      " 'HORIZON-MSCA-2024-INCO-01-01' 'HORIZON-MSCA-SNLS-2021-IBA'\n",
      " 'HORIZON-MSCA-2021-NCP-01-01' 'HORIZON-MSCA-2024-ALUMNI-IBA'\n",
      " 'HORIZON-MSCA-2023-ESP-IBA' 'HORIZON-MSCA-2024-FTP-01-01'\n",
      " 'HORIZON-MSCA-2021-SLOVENIAN-PRESIDENCY-IBA']\n",
      "INFRA : destination_code à null après traitement\n",
      "['HORIZON-INFRA-2022-GEANT-01-SGA' 'HORIZON-INFRA-2021-ICRI-IBA'\n",
      " 'HORIZON-INFRA-2023-SE-CONF-ART195-IBA' 'EUROHPC-2022-ES-01-01'\n",
      " 'HORIZON-INFRA-2021-EMERGENCY-01' 'HORIZON-INFRA-2023-ERIC-ART195-IBA'\n",
      " 'HORIZON-INFRA-2021-ESFRI20-IBA' 'HORIZON-INFRA-2024-SESAME-IBA'\n",
      " 'HORIZON-INFRA-2021-EMERGENCY-02' 'HORIZON-INFRA-2023-ES-CONF-ART195-IBA'\n",
      " 'HORIZON-INFRA-2024-BE-CONF-ART195-IBA' 'HORIZON-INFRA-2024-GEANT-01-SGA'\n",
      " 'HORIZON-INFRA-2024-IBA-ICRI']\n",
      "HOR3 : thema_code à null après traitement\n",
      "['EIT-KICS-2021-TECHNICAL' 'HORIZON-EIC-2021-EEN-01-01'\n",
      " 'HORIZON-EIC-2021-NCP-01-01' 'HORIZON-EIC-2021-PUBLICBUY-01-01'\n",
      " 'HORIZON-EIC-2021-STARTUPEU-01-01' 'HORIZON-EIC-2022-AIBP-TRAINING-IBA'\n",
      " 'HORIZON-EIC-2022-AIBTRTOOL-IBA' 'HORIZON-EIC-2022-BOOSTER-IBA'\n",
      " 'HORIZON-EIC-2022-COMMUNITIES-01-01' 'HORIZON-EIC-2022-GENDER-01-01'\n",
      " 'HORIZON-EIC-2022-STARTUPEU-01-01' 'HORIZON-EIC-2022-UKRAINIANTECH-01-01'\n",
      " 'HORIZON-EIC-2023-BOOSTER-IBA-01-01' 'HORIZON-EIC-2023-INNOVPRO-01-01'\n",
      " 'HORIZON-EIC-2023-PARTNERS-01-01' 'HORIZON-EIC-2023-SPAIN-IBA-01-01'\n",
      " 'HORIZON-EIC-2023-SWEDPC-IBA-01-01' 'HORIZON-EIC-2023-TALENTS-01-01'\n",
      " 'HORIZON-EIC-2023-XIR-IBA-01-01' 'HORIZON-EIC-2024-BOOSTER'\n",
      " 'HORIZON-EIC-2024-BOOSTER-IBA-01' 'HORIZON-EIT-2021-KIC-DESIGN-EITCCI'\n",
      " 'HORIZON-EIT-2022-KIC-STARTUP-EITCCI' 'HORIZON-EIT-2023-2025-HEI'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Regional-Innovation'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Shared-Services'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Strategic-ATF'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Strategic-Education'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Strategic-Outreach'\n",
      " 'HORIZON-EIT-2023-25-Cross-KIC-Strategic-Synergies'\n",
      " 'HORIZON-EIT-2023-25-TI' 'HORIZON-EIT-2023-NCP-CANCELLED'\n",
      " 'HORIZON-EIT-2024-CRM-IBA' 'HORIZON-EIT-2024-EAMA-IBA'\n",
      " 'HORIZON-EIT-2024-ERMA-IBA' 'HORIZON-EIT-2024-MOC-IBA'\n",
      " 'Horizon-EIT-2024-NCP-IBA']\n",
      "HOR4 : thema_code à null après traitement\n",
      "['HORIZON-WIDERA-2021-ESOF-IBA' 'HORIZON-WIDERA-2021-EUCYS-IBA'\n",
      " 'HORIZON-WIDERA-2021-NCP-IBA' 'HORIZON-WIDERA-2021-RESAVER-IBA'\n",
      " 'HORIZON-WIDERA-2022-CONF-RI-IBA' 'HORIZON-WIDERA-2022-WIRE-IBA'\n",
      " 'HORIZON-WIDERA-2023-ESOF-IBA' 'HORIZON-WIDERA-2023-EU-CECR-IBA'\n",
      " 'HORIZON-WIDERA-2023-EUCYS-IBA' 'HORIZON-WIDERA-2023-RESAVER-IBA'\n",
      " 'HORIZON-WIDERA-2024-EUCYS-IBA' 'HORIZON-WIDERA-2024-WIRE-IBA']\n",
      "- attention des cellules sont vides dans tab: Index(['destination_lib', 'destination_name_fr', 'destination_name_en'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zfriant\\Documents\\GitHub\\pcri\\step1_mainData\\topics.py:171: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'SESAR' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  top.loc[mask, 'destination_code'] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size merged after add topics: 102295\n",
      "\n",
      "### ACTIONS\n",
      "1- call sans action:\n",
      "                                      call_id\n",
      "24693  HORIZON-HLTH-2022-DISEASE-06-two-stage\n",
      "\n",
      "- size merged after add actions: 102295\n",
      "\n",
      "\n",
      "### CALLS\n",
      "\n",
      "### CALLS+MERGED\n",
      "2 - CALL_ID de merged -> nb call+deadline: 530, nb call unique: 492 \n",
      "\n",
      "### CALLS to CHECK\n",
      "- CALLS de base calls with merge call_id ->\n",
      "nb call+deadline: 537, nb call unique: 492 \n",
      "2- si calls pas dans call_id :\n",
      "                             call_id call_deadline\n",
      "231  HORIZON-EIC-2023-BOOSTER-IBA-01    2023-07-05\n",
      "248  HORIZON-EIC-2024-ACCELERATOR-02    2024-10-03\n",
      "251  HORIZON-EIC-2024-BOOSTER-IBA-01    2024-09-04\n",
      "252  HORIZON-EIC-2024-BOOSTER-IBA-01    2024-11-14\n",
      "467       HORIZON-MSCA-2021-SNLS-IBA    2021-07-27\n",
      "505    HORIZON-WIDERA-2022-ACCESS-07    2022-04-20\n",
      "522    HORIZON-WIDERA-2023-ACCESS-06    2024-09-26\n",
      "3- calls with multi deadline\n",
      "                                     call_id call_deadline   call_budget\n",
      "17                              ERC-2023-POC    2023-09-21  1.620000e+07\n",
      "69           HORIZON-EIC-2023-BOOSTER-IBA-01    2023-11-07  1.462724e+05\n",
      "79    HORIZON-HLTH-2022-DISEASE-06-two-stage    2022-09-06  1.759167e+08\n",
      "80    HORIZON-HLTH-2024-DISEASE-03-two-stage    2024-04-11  1.430066e+08\n",
      "81   HORIZON-HLTH-2022-STAYHLTH-01-two-stage    2022-09-06  1.713373e+08\n",
      "..                                       ...           ...           ...\n",
      "517            HORIZON-WIDERA-2023-ACCESS-06    2023-09-28  3.619712e+07\n",
      "521           HORIZON-EIC-2023-TRANSITION-01    2023-04-12  4.676831e+07\n",
      "524          HORIZON-EIC-2023-ACCELERATOR-01    2023-03-22  1.205308e+08\n",
      "533    HORIZON-CL6-2022-CIRCBIO-02-two-stage    2022-09-01  7.502058e+07\n",
      "536          HORIZON-EIC-2024-ACCELERATOR-02    2024-10-03  0.000000e+00\n",
      "\n",
      "[83 rows x 3 columns]\n",
      "- nbre call unique:492, nbre proposals:135585, fonds:43,639,586,740.5\n",
      "\n",
      "### CREATING FINAL PROJECTS\n",
      "size:102295\n",
      "\n",
      "### LOADING PARTICIPANTS data\n",
      "- no new columns\n",
      "- subv_net avant traitement: 44,801,576,700.0\n",
      "- suppression de 1434,\n",
      "modalités: partnerRemovalStatus\n",
      "TERMINATED              1343\n",
      "NOT_ACCEDED               91\n",
      "Name: count, dtype: int64\n",
      "4- projets dans participants et pas dans projects\n",
      "#FCT bugs_excel\n",
      "#FCT gps_col\n",
      "- result -> dowloaded:105091, retained part:103667, pb:1424, somme euContribution:44,757,770,154.3, somme netEuContribution:44,758,956,133.3\n",
      "- size part hors proj manquant: 100423\n",
      "### Participants ROLE\n",
      "- size part after role: 100423\n",
      "### ERC ROLE\n",
      "- size after erc_role: 100423\n",
      "\n",
      "### LOADING APPLICANTS data\n",
      "- size app au chargement: 473219\n",
      "- no new columns\n",
      "- var with null: ['shortName', 'countryCode', 'nutsCode', 'naceCode', 'budget', 'requestedGrant']\n",
      "#FCT gps_col\n",
      "- result -> dowloaded:473219, retained app:473219, pb:0, , somme requestedGrant:225,526,448,130.6\n",
      "- size app1 hors proj exclus: 463510\n",
      "\n",
      "### add to APPLICANT from PARTICIPANT\n",
      "1- ATTENTION ! vont être ajoutés les participants absents de proposals applicants 13\n",
      "- size app1 after add missing part1: 463523, subv: 207,742,891,674.0\n",
      "size acc_folio: 634\n",
      "size acc: 634\n",
      "### applicants ROLE\n",
      "### ERC ROLE\n",
      "- size after erc_role: 463523\n",
      "\n",
      "### check unicité des participants/projets\n",
      "#FCT bugs_excel\n",
      "\n",
      "### check unicité des applicants/projets\n",
      "#FCT bugs_excel\n",
      "\n",
      "### create LIEN\n",
      "app2: 463523 part2:100423\n",
      "- applicant uniquement lien1: 366542 reste à croiser -> app2: 96981\n",
      "jointure parfaite -> lien2: 56241\n",
      "reste à croiser -> app3: 40740 part3: 44182\n",
      "jointure sans ordernumber -> lien3: 36179\n",
      "reste à croiser -> app4: 4574 part4: 8013\n",
      "jointure sans participant_pic -> lien4: 673\n",
      "reste à croiser -> app5: 3901 part5: 7340\n",
      "jointure seulement avec generalpic -> lien5: 628\n",
      "reste à croiser -> app6: 3273 part6: 6712\n",
      "jointure avec seulement participant_pic -> lien6: 0\n",
      "- size lien: 470876\n",
      "\n",
      "### LOADING DEPARTMENT\n",
      "- size pp_app: 353303\n",
      "- size pp_part: 89566\n",
      "\n",
      "### NUTS avec LIEN\n",
      "- size nuts_a: 463523, size nuts_p: 100423\n",
      "size lien after add nuts: 470876, sans code_nuts: 0\n",
      "- size lien: 470876\n",
      "- first size entities: 283425\n",
      "#FCT gps_col\n",
      "- size entities 283422\n",
      "- size lien ap+pp+cc (tmp): 79350\n",
      "- size tmp+entities: 79350\n",
      "4 - RESOLU -> sans country\n",
      "- size entities with cc: 79350\n",
      "- END size entities: 79350\n",
      "- Tous les pics de lien sont dans entities\n",
      "### ENTITIES cleaning\n",
      "1 - ++state pour un pic/country; régler ci-dessous 2631\n",
      "3 - size entities after cleaning: 77991\n",
      "\n",
      "### ENTITIES SINGLE\n",
      "3 - size entities after one selection pic+cc: 77991\n",
      "- size entities_single:77991\n",
      "generalState\n",
      "VALIDATED     40342\n",
      "DECLARED      35818\n",
      "SLEEPING       1524\n",
      "DEPRECATED      278\n",
      "SUSPENDED        17\n",
      "BLOCKED          12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1 - nombre de pics OK\n",
      "- size entities_single:77991\n",
      "\n",
      "### ENTITIES INFO\n",
      "1- ATTENTION ! longueur finale de entities_info : 77991, longueur lien:77919\n",
      "- size entities_info: 77991\n",
      "\n",
      "### LOADING COUNTRY\n",
      "2 - info status countries ->\n",
      "-1 status in data ['THIRD' 'ASSOCIATED' 'THIRD-OCAF' 'MEMBER-STATE']\n",
      "- des valeurs nulles pour ces lignes:\n",
      "    countryCode country_name_mapping\n",
      "240         ZOE                  NaN\n",
      "241         ZOI                  NaN\n",
      "- des valeurs nulles pour ces lignes:\n",
      "    countryCode country_code_mapping\n",
      "240         ZOE                  NaN\n",
      "241         ZOI                  NaN\n",
      "- des valeurs nulles pour ces lignes:\n",
      "    countryCode article1\n",
      "8            AQ      NaN\n",
      "43           CK      NaN\n",
      "135          MH      NaN\n",
      "225          VA      NaN\n",
      "234          XK      NaN\n",
      "- des valeurs nulles pour ces lignes:\n",
      "    countryCode article2\n",
      "8            AQ      NaN\n",
      "43           CK      NaN\n",
      "135          MH      NaN\n",
      "225          VA      NaN\n",
      "234          XK      NaN\n",
      "\n",
      "### LOADING REF_SOURCE\n",
      "- size of ref_source : 503520\n",
      "### 2d - REF_SOURCE -> REF\n",
      "- size remplacement pic: 445\n",
      "- longueur de ref:79098\n",
      "- nb id: 79095\n",
      "- nb id after fill: 79067\n",
      "### create ENTITIES TMP pour ref\n",
      "- size entities_info before:77991, size entities_info+ref -> tmp:77991, generalPic unique:77919\n",
      "- entities_info en + -> (tmp2): 0\n",
      "- End size entities_tmp 77991\n",
      "size entities_tmp: 77991\n",
      "1 - After add ref to entities: 77991\n",
      "\n",
      "Index(['generalPic', 'legalName', 'businessName', 'id', 'id_secondaire',\n",
      "       'ZONAGE', 'country_code_mapping', 'countryCode_parent'],\n",
      "      dtype='object')\n",
      "2 - size entities si multi id -> entities_size_to_keep = 77995\n",
      "### merge ROR\n",
      "size entities_tmp after add ror_info: 77995\n",
      "## IDpaysage category\n",
      "- size paysage id à catégoriser:2269\n",
      "100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,\n",
      "- size resultat paysage_category:9414\n",
      "### CATEGORY paysage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zfriant\\Documents\\GitHub\\pcri\\api_requests\\paysage.py:536: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  paysage_category['category_end'] = pd.to_datetime(paysage_category['category_end'], format='mixed', errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "from main_library import *\n",
    "\n",
    "################################\n",
    "## data load / adjustements*\n",
    "extractDate = date_load()\n",
    "\n",
    "### pour l'instant ne fonctionne pas\n",
    "## demander à Eric de relancer la machine sur sandbox\n",
    "# get_call_info()\n",
    "\n",
    "# get_call_info_europa()\n",
    "\n",
    "proj = projects_load()\n",
    "proj_id_signed = proj.project_id.unique()\n",
    "\n",
    "prop = proposals_load()\n",
    "proj = proj_add_cols(prop, proj)\n",
    "\n",
    "stage_p =  ['REJECTED' ,'NO_MONEY' ,'MAIN', 'RESERVE', 'INELIGIBLE', 'WITHDRAWN', 'INADMISSIBLE', None]\n",
    "prop1 = proposals_status(prop, proj_id_signed, stage_p)  \n",
    "# np.save(\"data_files/applicants_columns.npy\", prop_cols)\n",
    "\n",
    "###########################################\n",
    "# proposals fix\n",
    "# projects missing from proposals\n",
    "call_to_integrate, call_miss = proposals_id_missing(prop1, proj, extractDate)\n",
    "\n",
    "# project data missing in proposals if call already in proposals then add this\n",
    "proj1 = proj_id_miss_fixed(prop1, proj, call_to_integrate)\n",
    "call_miss = list(set(call_miss)-set(call_to_integrate))\n",
    "proj = proj.loc[~proj.callId.isin(call_miss)]\n",
    "\n",
    "# merge proj + prop\n",
    "print('### MERGED PROPOSALS/PROJECTS')\n",
    "if len(proj1)==0:\n",
    "    prop2=pd.concat([proj,prop1], ignore_index= True)\n",
    "else:\n",
    "    prop2 = pd.concat([prop1, proj1, proj], ignore_index = True)\n",
    "\n",
    "prop2 = prop2.loc[~((prop2.status_code=='REJECTED')&(prop2.stage=='successful'))]\n",
    "print(f\"- result - merged all: {len(prop2)},\\n{prop2[['stage','status_code']].value_counts()}\")\n",
    "\n",
    "merged = copy.deepcopy(prop2)\n",
    "merged = dates_year(merged)\n",
    "merged = strings_v(merged)\n",
    "merged = url_to_clean(merged)\n",
    "merged.mask(merged=='', inplace=True)\n",
    "merged = empty_str_to_none(merged)      \n",
    "merged.rename(columns={\n",
    "    'freekw':'free_keywords',\n",
    "    'callDeadlineDate':'call_deadline', \n",
    "    'callId':'call_id', \n",
    "    'submissionDate':'submission_date',\n",
    "    'startDate':'start_date',\n",
    "    'endDate':'end_date', \n",
    "    'ecSignatureDate':'signature_date'}, inplace=True)\n",
    "\n",
    "if any(merged.loc[merged.stage=='successful', 'project_id'].value_counts()[merged.loc[merged.stage=='successful', 'project_id'].value_counts()> 1]):\n",
    "    print(merged.loc[merged.stage=='successful', 'project_id'].value_counts()[merged.loc[merged.stage=='successful', 'project_id'].value_counts()> 1])\n",
    "\n",
    "merged = merged_panels(merged)\n",
    "merged = merged_topics(merged)\n",
    "merged = merged_actions(merged)\n",
    "\n",
    "# calls list\n",
    "calls = call(PATH_SOURCE+FRAMEWORK+'/')\n",
    "\n",
    "print(\"\\n### CALLS+MERGED\")\n",
    "if len(merged.loc[merged.call_id.isnull()])>0:\n",
    "        print(f\"1 - ATTENTION : manque des call_id: {merged.loc[merged.call_id.isnull(), 'project_id']}\")\n",
    "else:\n",
    "    call_id = merged[['call_id', 'call_deadline']].drop_duplicates()\n",
    "    print(f\"2 - CALL_ID de merged -> nb call+deadline: {len(call_id)}, nb call unique: {call_id.call_id.nunique()} \")\n",
    "\n",
    "calls = calls_to_check(calls, call_id)\n",
    "\n",
    "projects = projects_complete_cleaned(merged, extractDate)\n",
    "\n",
    "#############################################################\n",
    "##### PARTICIPATIONS\n",
    "part = participants_load(proj)\n",
    "# conserve uniquement les projets présents dans proposals et applicants\n",
    "part = part.loc[part.project_id.isin(projects.project_id.unique())]\n",
    "print(f\"- size part hors proj manquant: {len(part)}\")\n",
    "part = part_role_type(part)\n",
    "part = erc_role(part, projects)\n",
    "\n",
    "#### APPLICANTS\n",
    "app = applicants_load(prop)\n",
    "# conserve uniquement les projets présents dans proposals et applicants\n",
    "app1 = app.loc[app.project_id.isin(projects.project_id.unique())] \n",
    "print(f\"- size app1 hors proj exclus: {len(app1)}\")\n",
    "\n",
    "app_missing_pid = projects.loc[(projects.stage=='evaluated')&(~projects.project_id.isin(app1.project_id.unique())), 'project_id'].unique()\n",
    "tmp = part[part.project_id.isin(app_missing_pid)]\n",
    "app1 = part_miss_app(tmp, app1)\n",
    "\n",
    "#redressement accelerator\n",
    "acc_folio = pd.read_csv(f\"{PATH_SOURCE}{FRAMEWORK}/eic_fund_portfolio.csv\", sep=';', dtype={'PROPOSAL_NBR':str})\n",
    "print(f\"size acc_folio: {len(acc_folio)}\")\n",
    "acc = (app1.loc[(app1.project_id.isin(acc_folio.PROPOSAL_NBR.unique()))&(app1.role=='Coordinator'),['project_id', 'role']]\n",
    "       .merge(acc_folio[['PROPOSAL_NBR','GRANT_REQUESTED']], how='inner', left_on='project_id', right_on='PROPOSAL_NBR')\n",
    "       .drop(columns='PROPOSAL_NBR'))\n",
    "print(f\"size acc: {len(acc)}\")\n",
    "app1 = app1.merge(acc, how='left', on=['project_id', 'role'])\n",
    "app1.loc[app1.requestedGrant.isnull(), 'requestedGrant'] = app1.GRANT_REQUESTED\n",
    "app1.drop(columns=['GRANT_REQUESTED'], inplace=True)\n",
    "\n",
    "app1 = app_role_type(app1)\n",
    "app1 = erc_role(app1, projects)\n",
    "\n",
    "del app\n",
    "\n",
    "####\n",
    "# verification Etat des participations\n",
    "part = check_multiP_by_proj(part)\n",
    "app1 = check_multiA_by_proj(app1)\n",
    "\n",
    "\n",
    "### STEP2\n",
    "lien = merged_partApp(app1, part)\n",
    "lien = nuts_lien(app1, part, lien)\n",
    "lien.to_pickle(f\"{PATH_CLEAN}lien.pkl\")\n",
    "\n",
    "# ENTITIES\n",
    "entities = entities_load(lien)\n",
    "entities_single = entities_single_create(entities, lien)\n",
    "entities_info = entities_info_create(entities_single, lien)\n",
    "\n",
    "list_codeCountry = entities_info.countryCode.unique()\n",
    "countries = country_load(FRAMEWORK, list_codeCountry)\n",
    "\n",
    "### step3\n",
    "\n",
    "# ##################################\n",
    "# # nouvelle actualisation ; à executer UNE FOIS\n",
    "# ref_source = ref_source_load('ref')\n",
    "# result, check_id_liste, identification = first_update(ref_source, entities_info, countries)\n",
    "\n",
    "# # vérifier dans excel les nouveaux ID PATH_WORK/_check_id_result.xlsx\n",
    "# IDchecking_results(result, check_id_liste, identification)\n",
    "\n",
    "# id_verified = ID_resultChecked()\n",
    "# new_ref_source(id_verified, ref_source, extractDate, part, app1, entities_single, countries)\n",
    "\n",
    "# ########################################################################################################\n",
    "\n",
    "# chargement du nouveau ref_source\n",
    "ref_source = ref_source_load('ref')\n",
    "ref, genPic_to_new = ref_source_2d_select(ref_source, 'HE')\n",
    "entities_tmp = entities_tmp_create(entities_info, countries, ref)\n",
    "print(f\"size entities_tmp: {len(entities_tmp)}\")\n",
    "entities_tmp = entities_for_merge(entities_tmp)\n",
    "\n",
    "### Executer uniquement si besoin\n",
    "# lid_source, unknow_list = ID_entities_list(ref_source)\n",
    "# ror = ror_getRefInfo(lid_source)\n",
    "# siren_siret = get_siret_siege(lid_source)\n",
    "# paysage_id = ID_to_IDpaysage(lid_source, siren_siret)\n",
    "# paysage, paysage_mires = paysage_getRefInfo(lid_source, siren_siret, paysage_old=None)\n",
    "# paysage_category = IDpaysage_category(paysage)\n",
    "# sirene = get_sirene(lid_source, sirene_old=None)\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "### merge entities_tmp + referentiel\n",
    "# ROR\n",
    "### si besoin de charger ror pickle\n",
    "ror = pd.read_pickle(f\"{PATH_REF}ror_df.pkl\")\n",
    "entities_tmp = merge_ror(entities_tmp, ror)\n",
    "\n",
    "# PAYSAGE\n",
    "### si besoin de charger paysage pickle\n",
    "paysage = pd.read_pickle(f\"{PATH_REF}paysage_df.pkl\")\n",
    "paysage_category = pd.read_pickle(f\"{PATH_SOURCE}paysage_category.pkl\")\n",
    "# paysage_category = IDpaysage_category(paysage)\n",
    "cat_filter = category_paysage(paysage_category)\n",
    "entities_tmp = merge_paysage(entities_tmp, paysage, cat_filter)\n",
    "sirene = pd.read_pickle(f\"{PATH_REF}sirene_df.pkl\")\n",
    "entities_tmp = merge_sirene(entities_tmp, sirene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### create ENTITIES TMP pour ref\n",
      "- size entities_info before:77991, size entities_info+ref -> tmp:77991, generalPic unique:77919\n",
      "- entities_info en + -> (tmp2): 0\n",
      "- End size entities_tmp 77991\n",
      "size entities_tmp: 77991\n",
      "1 - After add ref to entities: 77991\n",
      "\n",
      "Index(['generalPic', 'legalName', 'businessName', 'id', 'id_secondaire',\n",
      "       'ZONAGE', 'country_code_mapping', 'countryCode_parent'],\n",
      "      dtype='object')\n",
      "2 - size entities si multi id -> entities_size_to_keep = 77995\n",
      "### merge ROR\n",
      "size entities_tmp after add ror_info: 77995\n",
      "### CATEGORY paysage\n",
      "### merge PAYSAGE\n",
      "- doublons PIC      generalPic                                          legalName  \\\n",
      "98     876941596                       WEIR MINERALS EUROPE LIMITED   \n",
      "99     876941596                       WEIR MINERALS EUROPE LIMITED   \n",
      "152    877256167                                  EURACTIV MEDIA BV   \n",
      "153    877256167                             EURACTIV MEDIA NETWORK   \n",
      "299    877625834  NEPTUNE LINES SHIPPING AND MANAGING ENTERPRISE...   \n",
      "...          ...                                                ...   \n",
      "77948  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77949  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77950  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77961  999990267  MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISS...   \n",
      "77962  999990267  MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISS...   \n",
      "\n",
      "        businessName          id id_secondaire ZONAGE country_code_mapping  \\\n",
      "98     WEIR MINERALS         NaN           NaN    NaN                  ESP   \n",
      "99     WEIR MINERALS         NaN           NaN    NaN                  GBR   \n",
      "152             None         NaN           NaN    NaN                  BEL   \n",
      "153             None         NaN           NaN    NaN                  NLD   \n",
      "299             None         NaN           NaN    NaN                  GRC   \n",
      "...              ...         ...           ...    ...                  ...   \n",
      "77948           EMBL  R03mstc592           NaN    ZOE                  ESP   \n",
      "77949           EMBL  R03mstc592           NaN    ZOE                  ITA   \n",
      "77950           EMBL  R03mstc592           NaN    ZOE                  GBR   \n",
      "77961            MPG  R01hhn8329           NaN    NaN                  DEU   \n",
      "77962            MPG  R01hhn8329           NaN    NaN                  NLD   \n",
      "\n",
      "      countryCode_parent   id_extend unused_parent  ... paysage_cj_name  \\\n",
      "98                    ES         NaN           NaN  ...             NaN   \n",
      "99                    UK         NaN           NaN  ...             NaN   \n",
      "152                   BE         NaN           NaN  ...             NaN   \n",
      "153                   NL         NaN           NaN  ...             NaN   \n",
      "299                   EL         NaN           NaN  ...             NaN   \n",
      "...                  ...         ...           ...  ...             ...   \n",
      "77948                 ES  R03mstc592           NaN  ...             NaN   \n",
      "77949                 IT  R03mstc592           NaN  ...             NaN   \n",
      "77950                 UK  R03mstc592           NaN  ...             NaN   \n",
      "77961                 DE  R01hhn8329           NaN  ...             NaN   \n",
      "77962                 NL  R01hhn8329           NaN  ...             NaN   \n",
      "\n",
      "      sector                          entities_name entities_acronym  \\\n",
      "98       NaN                                    NaN              NaN   \n",
      "99       NaN                                    NaN              NaN   \n",
      "152      NaN                                    NaN              NaN   \n",
      "153      NaN                                    NaN              NaN   \n",
      "299      NaN                                    NaN              NaN   \n",
      "...      ...                                    ...              ...   \n",
      "77948    NaN  European Molecular Biology Laboratory             EMBL   \n",
      "77949    NaN  European Molecular Biology Laboratory             EMBL   \n",
      "77950    NaN  European Molecular Biology Laboratory             EMBL   \n",
      "77961    NaN                     Max Planck Society              MPG   \n",
      "77962    NaN                     Max Planck Society              MPG   \n",
      "\n",
      "      siren_end_date paysage_siren  nb paysage_category_id paysage_category  \\\n",
      "98               NaN           NaN NaN                 NaN              NaN   \n",
      "99               NaN           NaN NaN                 NaN              NaN   \n",
      "152              NaN           NaN NaN                 NaN              NaN   \n",
      "153              NaN           NaN NaN                 NaN              NaN   \n",
      "299              NaN           NaN NaN                 NaN              NaN   \n",
      "...              ...           ...  ..                 ...              ...   \n",
      "77948            NaN           NaN NaN                 NaN              NaN   \n",
      "77949            NaN           NaN NaN                 NaN              NaN   \n",
      "77950            NaN           NaN NaN                 NaN              NaN   \n",
      "77961            NaN           NaN NaN                 NaN              NaN   \n",
      "77962            NaN           NaN NaN                 NaN              NaN   \n",
      "\n",
      "       paysage_category_priority  \n",
      "98                           NaN  \n",
      "99                           NaN  \n",
      "152                          NaN  \n",
      "153                          NaN  \n",
      "299                          NaN  \n",
      "...                          ...  \n",
      "77948                        NaN  \n",
      "77949                        NaN  \n",
      "77950                        NaN  \n",
      "77961                        NaN  \n",
      "77962                        NaN  \n",
      "\n",
      "[149 rows x 23 columns]\n",
      "size entities_tmp after add paysage_info: 77995\n",
      "### merge SIRENE\n",
      "1 - size sirene : 15655\n",
      "2 - size sirene : 15655\n",
      "3 - A vérifier -> liste des noms à traiter:\n",
      "                                    ens denom_us  \\\n",
      "0   MUSEE HISTORIQUE DE L HYDRAVIATION     None   \n",
      "1          MUSEE ET SITE ARCHEOLOGIQUE     None   \n",
      "2                                  NaN     None   \n",
      "3                                  NaN     None   \n",
      "4                                  NaN     None   \n",
      "5                                  NaN     None   \n",
      "6                                  NaN     None   \n",
      "7                                  NaN     None   \n",
      "8                                  NaN     None   \n",
      "9                                  NaN     None   \n",
      "10                                 NaN     None   \n",
      "11                                 NaN     None   \n",
      "\n",
      "                                               nom_ul  \n",
      "0                              COMMUNE DE BISCARROSSE  \n",
      "1                                DEPARTEMENT DU RHONE  \n",
      "2                                           MODUL-BIO  \n",
      "3   CHARLES RIVER LABORATORIES FRANCE SAFETY ASSES...  \n",
      "4            UNION INTERNAT TUBERCULOSE MALADIE RESPI  \n",
      "5                                           NEOBIOSYS  \n",
      "6                               SOLIDARITES JEUNESSES  \n",
      "7                                   NATURAL SOLUTIONS  \n",
      "8                         SOLETANCHE BACHY ENTREPRISE  \n",
      "9                                           COFIROUTE  \n",
      "10             INST EUR ENTR PROPRIETE INTELLECTUELLE  \n",
      "11              ORGANISATION PRODUCTEURS THON CONGELE  \n",
      "#####\n",
      "5 - si ++ lignes / pics :       generalPic                                          legalName  \\\n",
      "98     876941596                       WEIR MINERALS EUROPE LIMITED   \n",
      "99     876941596                       WEIR MINERALS EUROPE LIMITED   \n",
      "152    877256167                                  EURACTIV MEDIA BV   \n",
      "153    877256167                             EURACTIV MEDIA NETWORK   \n",
      "299    877625834  NEPTUNE LINES SHIPPING AND MANAGING ENTERPRISE...   \n",
      "...          ...                                                ...   \n",
      "77932  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77933  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77934  999988230              EUROPEAN MOLECULAR BIOLOGY LABORATORY   \n",
      "77945  999990267  MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISS...   \n",
      "77946  999990267  MAX-PLANCK-GESELLSCHAFT ZUR FORDERUNG DER WISS...   \n",
      "\n",
      "        businessName          id id_secondaire ZONAGE country_code_mapping  \\\n",
      "98     WEIR MINERALS         NaN           NaN    NaN                  ESP   \n",
      "99     WEIR MINERALS         NaN           NaN    NaN                  GBR   \n",
      "152             None         NaN           NaN    NaN                  BEL   \n",
      "153             None         NaN           NaN    NaN                  NLD   \n",
      "299             None         NaN           NaN    NaN                  GRC   \n",
      "...              ...         ...           ...    ...                  ...   \n",
      "77932           EMBL  R03mstc592           NaN    ZOE                  ESP   \n",
      "77933           EMBL  R03mstc592           NaN    ZOE                  ITA   \n",
      "77934           EMBL  R03mstc592           NaN    ZOE                  GBR   \n",
      "77945            MPG  R01hhn8329           NaN    NaN                  DEU   \n",
      "77946            MPG  R01hhn8329           NaN    NaN                  NLD   \n",
      "\n",
      "      countryCode_parent   id_extend unused_parent  ... siren_end_date  \\\n",
      "98                    ES         NaN           NaN  ...            NaN   \n",
      "99                    UK         NaN           NaN  ...            NaN   \n",
      "152                   BE         NaN           NaN  ...            NaN   \n",
      "153                   NL         NaN           NaN  ...            NaN   \n",
      "299                   EL         NaN           NaN  ...            NaN   \n",
      "...                  ...         ...           ...  ...            ...   \n",
      "77932                 ES  R03mstc592           NaN  ...            NaN   \n",
      "77933                 IT  R03mstc592           NaN  ...            NaN   \n",
      "77934                 UK  R03mstc592           NaN  ...            NaN   \n",
      "77945                 DE  R01hhn8329           NaN  ...            NaN   \n",
      "77946                 NL  R01hhn8329           NaN  ...            NaN   \n",
      "\n",
      "      paysage_siren  nb paysage_category_id paysage_category  \\\n",
      "98              NaN NaN                 NaN              NaN   \n",
      "99              NaN NaN                 NaN              NaN   \n",
      "152             NaN NaN                 NaN              NaN   \n",
      "153             NaN NaN                 NaN              NaN   \n",
      "299             NaN NaN                 NaN              NaN   \n",
      "...             ...  ..                 ...              ...   \n",
      "77932           NaN NaN                 NaN              NaN   \n",
      "77933           NaN NaN                 NaN              NaN   \n",
      "77934           NaN NaN                 NaN              NaN   \n",
      "77945           NaN NaN                 NaN              NaN   \n",
      "77946           NaN NaN                 NaN              NaN   \n",
      "\n",
      "      paysage_category_priority siret_closeDate id_m siren  siege  \n",
      "98                          NaN             NaN  NaN   NaN    NaN  \n",
      "99                          NaN             NaN  NaN   NaN    NaN  \n",
      "152                         NaN             NaN  NaN   NaN    NaN  \n",
      "153                         NaN             NaN  NaN   NaN    NaN  \n",
      "299                         NaN             NaN  NaN   NaN    NaN  \n",
      "...                         ...             ...  ...   ...    ...  \n",
      "77932                       NaN             NaN  NaN   NaN    NaN  \n",
      "77933                       NaN             NaN  NaN   NaN    NaN  \n",
      "77934                       NaN             NaN  NaN   NaN    NaN  \n",
      "77945                       NaN             NaN  NaN   NaN    NaN  \n",
      "77946                       NaN             NaN  NaN   NaN    NaN  \n",
      "\n",
      "[149 rows x 27 columns]\n",
      "after sirene: 77995\n"
     ]
    }
   ],
   "source": [
    "entities_tmp = entities_tmp_create(entities_info, countries, ref)\n",
    "print(f\"size entities_tmp: {len(entities_tmp)}\")\n",
    "entities_tmp = entities_for_merge(entities_tmp)\n",
    "\n",
    "### Executer uniquement si besoin\n",
    "# lid_source, unknow_list = ID_entities_list(ref_source)\n",
    "# ror = ror_getRefInfo(lid_source)\n",
    "# siren_siret = get_siret_siege(lid_source)\n",
    "# paysage_id = ID_to_IDpaysage(lid_source, siren_siret)\n",
    "# paysage, paysage_mires = paysage_getRefInfo(lid_source, siren_siret, paysage_old=None)\n",
    "# paysage_category = IDpaysage_category(paysage)\n",
    "# sirene = get_sirene(lid_source, sirene_old=None)\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "### merge entities_tmp + referentiel\n",
    "# ROR\n",
    "### si besoin de charger ror pickle\n",
    "ror = pd.read_pickle(f\"{PATH_REF}ror_df.pkl\")\n",
    "entities_tmp = merge_ror(entities_tmp, ror)\n",
    "\n",
    "# PAYSAGE\n",
    "### si besoin de charger paysage pickle\n",
    "paysage = pd.read_pickle(f\"{PATH_REF}paysage_df.pkl\")\n",
    "paysage_category = pd.read_pickle(f\"{PATH_SOURCE}paysage_category.pkl\")\n",
    "# paysage_category = IDpaysage_category(paysage)\n",
    "cat_filter = category_paysage(paysage_category)\n",
    "entities_tmp = merge_paysage(entities_tmp, paysage, cat_filter)\n",
    "sirene = pd.read_pickle(f\"{PATH_REF}sirene_df.pkl\")\n",
    "entities_tmp = merge_sirene(entities_tmp, sirene)\n",
    "\n",
    "entities_tmp.loc[(~entities_tmp.id.isnull())&(entities_tmp.entities_id.isnull()), 'entities_id'] = entities_tmp.id\n",
    "\n",
    "if any(entities_tmp.siren.str.contains(';', na=False)):\n",
    "    print(\"ATTENTION faire code pour traiter deux siren différents -> ce qui serait bizarre qu'il y ait 2 siren\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### traitement id_pic avec tiret\n",
      "- size entities_tmp: 77995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def IDpic(entities_tmp):\n",
    "    print(\"\\n### traitement id_pic avec tiret\")\n",
    "    # IDENT with '-' : traitement des identifiants avec '-' pour regrouper multi-pic non identifiés \n",
    "    if not entities_tmp.loc[entities_tmp.id.str.contains('-', na=False)].empty:\n",
    "        pic_dash = (entities_tmp.loc[entities_tmp.id.str.contains('-', na=False), ['generalPic', 'entities_id']]\n",
    "        .drop_duplicates()\n",
    "        .drop(columns='generalPic')\n",
    "        .assign(pic_d = entities_tmp.entities_id.str.split('-').str[0]))\n",
    "        print(f\"- size entities pic_dash: {len(pic_dash)}\")\n",
    "        dash = (pic_dash.merge(entities_tmp, how='inner', left_on='pic_d', right_on='generalPic', suffixes=['_x',''])\n",
    "                .drop(columns=['entities_id_x', 'pic_d'])).drop_duplicates()\n",
    "        \n",
    "        entities_tmp = entities_tmp.loc[~entities_tmp.entities_id.isin(dash.entities_id.unique())]\n",
    "        entities_tmp = pd.concat([entities_tmp, dash], ignore_index=True)\n",
    "        print(f\"- size entities_tmp: {len(entities_tmp)}\")\n",
    "\n",
    "    # IDENT pic : corriger appliquer les lignes ci-dessous uniuqument sur entities_id est null ou commence par pic\n",
    "    entities_tmp.loc[entities_tmp.entities_id.isnull(), 'entities_id'] = \"pic\"+entities_tmp.generalPic.map(str)\n",
    "    print(f\"- size entities_tmp: {len(entities_tmp)}\")\n",
    "    return entities_tmp\n",
    "entities_tmp = IDpic(entities_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### sourcer les identifiants pour getInformations\n"
     ]
    }
   ],
   "source": [
    "entities_tmp = entities_tmp.merge(get_source_ID(entities_tmp, 'entities_id'), how='left', on='entities_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accor,acri,ad industries,aeroports de paris,agence reuters,air france,air liquide,airbus,airbusdefense,airbushelico,akira,akka technologies,alcen,alfa,algosource,alpha,alstom,altair,alten,amplitude laser,anteric,aperam,aqualande,arcelormittal,areva,ariane,arjowiggins,arkema,artal technologies,artelia,asfalp,assystem,atos,avions,awt,axa,bayer,bconstr,bimmo,bio rad,bnp,bonduelle,brgm sa,btelecom,ca,canon,capgemini,caraholding,cargill,carrefour,centum electronics,clarivate analytics,cma,cmi,cnim,colas,collecte localisation satellite,constellium,continental,coriolis composites,cs,danone,dassault,dcns,decathlon,doris,draka,ds smith,duvarry,edfRTE,eiffage,elvia,engie,equip aero,eramet,ericsson,ernst,esi,essilor,esterline,eurofins,faiveley,faurecia,fibre,fives,flex,foritech,geenergie,gemedical,giat,gobain,h51,hewlett,hitachi,hitec premium,horiba,hp,idemia,ifv,ineos,intel,ixcore,xlabo meteo essai,lactalis,lafarge,latecoere,legrand,lesieur,limagrain,loiretech,lord,lp2c,lvmh,lynred,mbda,merial,merieux,mersen,meteo,michelin,microchip,microsoft,mondelez,mxm,nestle,nexter,nikon,nokia,novalix,novasep,orange,orano,papier,parrot,pelican venture,pernod,peugeot,pfizer,pierre fabre,poste,ppg industries,publicis,ratp,recif,renault,rescoll,rhodia,safran,sagemcom,samsung,sanofi,scalian,schlumberger,schneider electric,schneider holding,serma,servier,siemens,silvaco,skf,sncf,socgen,sogeclair,soitec,sopra,stago,stmicro,sts,suez,sunaero,tech,technicolor,technip,tereos,test,thales,timab,toshiba,total,transdev,ubisoft,umicore,union invivo,urbanis,valagro,valeo,vallourec,veolia,veritas,vibra groupe,vinci,vinci tech,vinci_auto,virbac,visteon electronics,vivescia,volkswagen,volvo,xerox,\n",
      "1 - Nb de groupes dans gr: 198\n",
      "Groupes non traités (n'existent plus): {'silkan', 'gemalto', 'xlabo meteo essai', 'egis', 'sherpa engineering', 'semco engineering'}\n",
      "4 - size groupe 9268\n",
      "ok -> 9268\n",
      "taille de entities_tmp avant groupe:77998\n"
     ]
    }
   ],
   "source": [
    "def groupe_treatment(df, output):\n",
    "    import pandas as pd, numpy as np, openpyxl, warnings, copy\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    PATH_REF = \"C:/Users/zfriant/Documents/OneDrive/PCRI/eCorda_datas/datas_reference/\"\n",
    "\n",
    "    liste = pd.read_excel(f\"{PATH_REF}_groupes_liste.xlsx\", dtype=object, keep_default_na=False, sheet_name = \"liste\")\n",
    "    ge = openpyxl.load_workbook(f\"{PATH_REF}{df}.xlsm\").sheetnames[1:]\n",
    "#     ge = liste_pcri\n",
    "    \n",
    "    gr = pd.DataFrame()\n",
    "    verif = pd.DataFrame()\n",
    "\n",
    "    for i in ge:\n",
    "        x = pd.read_excel(f\"{PATH_REF}{df}.xlsm\", sheet_name=i, dtype=str)\n",
    "        \n",
    "        if len(x)>0:\n",
    "            x.dropna(axis = 0, how = 'all', inplace = True)\n",
    "            \n",
    "            if 'Identifiant unité légale' in x.columns:\n",
    "                x = x.rename(columns={'Identifiant unité légale':'siren'})\n",
    "            elif 'Unité légale' in x.columns:\n",
    "                x = x.rename(columns={'Unité légale':'siren'})\n",
    "                \n",
    "            if 'Unité légale étrangère ?' in x.columns:  \n",
    "                x = x.loc[x['Unité légale étrangère ?']==\"Non\"]  \n",
    "            else:\n",
    "                pass\n",
    " \n",
    "            if 'Taux détention' in x.columns:\n",
    "                x = x.assign(detention = x['Taux détention'].str.replace(',', '.').astype(float))\n",
    "            elif 'Taux integration' in x.columns:\n",
    "                x = x.assign(detention = x['Taux integration'].str.replace(',', '.').astype(float))\n",
    "                \n",
    "            x = x.loc[~(x['detention'] < 50.)]\n",
    "                      \n",
    "            print(i, end=\",\")\n",
    "            verif = pd.concat([verif, x], ignore_index=True)\n",
    "        \n",
    "\n",
    "            x['GROUPE'] = i\n",
    "            x = x.merge(liste, how='inner', on=\"GROUPE\")\n",
    "            gr = pd.concat([gr, x], ignore_index=True)\n",
    "\n",
    "    print(f\"\\n1 - Nb de groupes dans gr: {gr.ordre.nunique()}\\nGroupes non traités (n'existent plus): {set(ge)-set(gr.GROUPE.unique())}\")\n",
    "    \n",
    "    # verif_na <- gr[apply(gr, 2, function(x) any(is.na(x)))]\n",
    "    if gr[gr.siren.isnull()].empty:\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"2 - Attention des siren sont null\\n{gr.loc[gr.siren.isnull(), ['Raison sociale', 'groupe_acronym', 'ordre']]}\")\n",
    "        gr=gr.loc[~gr.siren.isnull()]\n",
    "\n",
    "    # # contrôle de la longueur des siren ; ajout de 0 devant si < 9\n",
    "    for i in gr.columns:\n",
    "        if gr[i].dtype == 'str':\n",
    "            gr[i] = gr[i].map(str.strip)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    if any(9-gr.siren.str.len())>0:\n",
    "        gr['siren'] = gr['siren'].str.rjust(9, fillchar='0')\n",
    "    else:\n",
    "        print(f\"3 - autre pb avec le siren {gr[gr.siren.str.len()!=9][['siren', 'GROUPE', 'long']]}\")\n",
    "\n",
    "\n",
    "    groupe = copy.deepcopy(gr)[['siren', 'Etat', 'Date de fin', 'GROUPE', 'ordre', 'ex_groupe', 'groupe_name', 'groupe_acronym', 'groupe_sector']]\n",
    "    print(f\"4 - size groupe {len(groupe)}\")\n",
    "\n",
    "    groupe['n'] = groupe.groupby('siren', dropna=False)['siren'].transform('count')\n",
    "\n",
    "    groupe = groupe.loc[~((groupe.n>1) & ((groupe.Etat.isin([\"Cessée\", \"Inactive économique\", \"Inactive statistique\"])) | ~(groupe['Date de fin'].isnull())))]\n",
    "    groupe['n'] = groupe.groupby('siren', dropna=False)['siren'].transform('count')\n",
    "\n",
    "    if any(groupe.n>1):\n",
    "        print(f\"vérifier dans groupe les doublons n>1\\n{groupe[groupe.n>1]}\")\n",
    "    else:\n",
    "        print(f\"ok -> {len(groupe)}\")\n",
    "\n",
    "\n",
    "    groupe['groupe_id'] = \"gent\"+groupe.ordre.map(str)\n",
    "    groupe = groupe[['siren', 'groupe_name', 'groupe_acronym', 'groupe_id', 'groupe_sector']]    \n",
    "    groupe.siren = groupe.siren.astype(str)\n",
    "    \n",
    "    file_name = f\"{PATH_REF}{output}.pkl\"\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pd.to_pickle(groupe, file)\n",
    "    \n",
    "    return groupe\n",
    "groupe = groupe_treatment('groupe_prov', 'groupe')\n",
    "# wb=openpyxl.load_workbook(f\"{PATH_REF}groupe_prov.xlsm\").sheetnames[1:]\n",
    "### si besoin de charger groupe \n",
    "groupe = pd.read_pickle(f\"{PATH_REF}groupe.pkl\")\n",
    "print(f\"taille de entities_tmp avant groupe:{len(entities_tmp)}\")\n",
    "# entities_tmp = merge_groupe(entities_tmp, groupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18733"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entities_tmp[entities_tmp.generalPic=='888071958']\n",
    "len(entities_tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcri-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
